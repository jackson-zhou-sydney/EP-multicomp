---
title: "Simulations for elastic net linear regression"
author: "Jackson Zhou"
date: "2022-10-09"
output: html_document
---

```{r Sourcing auxiliary functions}
source("../EP-general-auxiliaries.R")
source("Elastic-net-auxiliaries.R")
```

```{r Common simulation settings}
# Data
mu.kappa <- 0
sigma.2.kappa <- 10000
lambda.1 <- 0.8
lambda.2 <- 0.2

# Parameters
sigma <- 0.1
```

## Simulation 1

```{r Simulation 1}
set.seed(1)

# Data
n <- 200
p <- 50
X <- cbind(rep(1, n), scale(matrix(data = rnorm(n = n*(p - 1)), nrow = n)))

# Parameters
beta <- c(rbind(rep(2, p/2), rep(-2, p/2)))/p; beta[1:p/2] <- 0

# Response
y <- rnorm(n, X%*%beta, sigma)

# EP approximation
ep.res <- ep.approx(X, y, mu.kappa, sigma.2.kappa, 
                    lambda.1, lambda.2, eta = 0.5, alpha = 1, Q.star = 0.01*diag(2), r.star = rep(0, 2), prec = 0,
                    min.passes = 6, max.passes = 200, tol.factor = Inf, stop.factor = Inf , 
                    abs.thresh = 0.01, rel.thresh = 0.9, delta.limit = Inf, patience = 40, verbose = T)
ep.mu <- ep.res$mu
ep.Sigma <- ep.res$Sigma

# MCMC approximation
stan.res <- stan(file = "Elastic-net-model.stan",
                 data = list(N = n,
                             p = p,
                             X = X,
                             y = y,
                             mu_kappa = mu.kappa,
                             sigma_2_kappa = sigma.2.kappa,
                             lambda_1 = lambda.1,
                             lambda_2 = lambda.2),
                 chains = 1,
                 iter = 50000,
                 warmup = 5000,
                 init = "random") 

mcmc.samples <- rstan::extract(stan.res)$theta
mcmc.mu <- colMeans(mcmc.samples)
mcmc.Sigma <- var(mcmc.samples)

# Plotting results
for (j in 1:(p + 1)) {
  curve(demp(x, obs = mcmc.samples[, j]),
        from = mcmc.mu[j] - 5*sqrt(mcmc.Sigma[j, j]),
        to = mcmc.mu[j] + 5*sqrt(mcmc.Sigma[j, j]))
  abline(v = mcmc.mu[j], lty = 2)
  curve(dnorm(x, ep.mu[j], sqrt(ep.Sigma[j, j])), col = "red", add = TRUE)
}
```

## Simulation 2

```{r Simulation 2}
set.seed(1)

# Data
n <- 50
p <- 50
X <- cbind(rep(1, n), scale(matrix(data = rnorm(n = n*(p - 1)), nrow = n)))

# Parameters
beta <- c(rbind(rep(2, p/2), rep(-2, p/2)))/p; beta[1:p/2] <- 0

# Response
y <- rnorm(n, X%*%beta, sigma)

# EP approximation
ep.res <- ep.approx(X, y, mu.kappa, sigma.2.kappa, 
                    lambda.1, lambda.2, eta = 0.5, alpha = 1, Q.star = 0.01*diag(2), r.star = rep(0, 2), prec = 0,
                    min.passes = 6, max.passes = 200, tol.factor = Inf, stop.factor = Inf , 
                    abs.thresh = 0.01, rel.thresh = 0.9, delta.limit = Inf, patience = 40, verbose = T)
ep.mu <- ep.res$mu
ep.Sigma <- ep.res$Sigma

# MCMC approximation
stan.res <- stan(file = "Elastic-net-model.stan",
                 data = list(N = n,
                             p = p,
                             X = X,
                             y = y,
                             mu_kappa = mu.kappa,
                             sigma_2_kappa = sigma.2.kappa,
                             lambda_1 = lambda.1,
                             lambda_2 = lambda.2),
                 chains = 1,
                 iter = 50000,
                 warmup = 5000,
                 init = "random") 

mcmc.samples <- rstan::extract(stan.res)$theta
mcmc.mu <- colMeans(mcmc.samples)
mcmc.Sigma <- var(mcmc.samples)

# Plotting results
for (j in 1:(p + 1)) {
  curve(demp(x, obs = mcmc.samples[, j]),
        from = mcmc.mu[j] - 5*sqrt(mcmc.Sigma[j, j]),
        to = mcmc.mu[j] + 5*sqrt(mcmc.Sigma[j, j]))
  abline(v = mcmc.mu[j], lty = 2)
  curve(dnorm(x, ep.mu[j], sqrt(ep.Sigma[j, j])), col = "red", add = TRUE)
}
```

## Simulation 3

```{r Simulation 3}
set.seed(1)

# Data
n <- 10
p <- 50
X <- cbind(rep(1, n), scale(matrix(data = rnorm(n = n*(p - 1)), nrow = n)))

# Parameters
beta <- c(rbind(rep(2, p/2), rep(-2, p/2)))/p; beta[1:p/2] <- 0

# Response
y <- rnorm(n, X%*%beta, sigma)

# EP approximation
ep.res <- ep.approx(X, y, mu.kappa, sigma.2.kappa, 
                    lambda.1, lambda.2, eta = 0.5, alpha = 1, Q.star = 0.01*diag(2), r.star = rep(0, 2), prec = 0,
                    min.passes = 6, max.passes = 200, tol.factor = Inf, stop.factor = Inf , 
                    abs.thresh = 0.01, rel.thresh = 0.9, delta.limit = Inf, patience = 40, verbose = T)
ep.mu <- ep.res$mu
ep.Sigma <- ep.res$Sigma

# MCMC approximation
stan.res <- stan(file = "Elastic-net-model.stan",
                 data = list(N = n,
                             p = p,
                             X = X,
                             y = y,
                             mu_kappa = mu.kappa,
                             sigma_2_kappa = sigma.2.kappa,
                             lambda_1 = lambda.1,
                             lambda_2 = lambda.2),
                 chains = 1,
                 iter = 50000,
                 warmup = 5000,
                 init = "random") 

mcmc.samples <- rstan::extract(stan.res)$theta
mcmc.mu <- colMeans(mcmc.samples)
mcmc.Sigma <- var(mcmc.samples)

# Plotting results
for (j in 1:(p + 1)) {
  curve(demp(x, obs = mcmc.samples[, j]),
        from = mcmc.mu[j] - 5*sqrt(mcmc.Sigma[j, j]),
        to = mcmc.mu[j] + 5*sqrt(mcmc.Sigma[j, j]))
  abline(v = mcmc.mu[j], lty = 2)
  curve(dnorm(x, ep.mu[j], sqrt(ep.Sigma[j, j])), col = "red", add = TRUE)
}
```

## Benchmark 1

```{r Benchmark 1}
set.seed(1)

# Data
load("../Benchmark-data/efron2004.Rdata")
X <- cbind(1, scale(efron2004$x))
y <- as.vector(efron2004$y)
n <- nrow(X)
p <- ncol(X)

# EP approximation
ep.res <- ep.approx(X, y, mu.kappa, sigma.2.kappa, 
                    lambda.1, lambda.2, eta = 0.5, alpha = 1, Q.star = 0.01*diag(2), r.star = rep(0, 2), prec = 0,
                    min.passes = 6, max.passes = 200, tol.factor = Inf, stop.factor = Inf , 
                    abs.thresh = 0.01, rel.thresh = 0.9, delta.limit = Inf, patience = 40, verbose = T)
ep.mu <- ep.res$mu
ep.Sigma <- ep.res$Sigma

# MCMC approximation
stan.res <- stan(file = "Elastic-net-model.stan",
                 data = list(N = n,
                             p = p,
                             X = X,
                             y = y,
                             mu_kappa = mu.kappa,
                             sigma_2_kappa = sigma.2.kappa,
                             lambda_1 = lambda.1,
                             lambda_2 = lambda.2),
                 chains = 1,
                 iter = 50000,
                 warmup = 5000,
                 init = "random") 

mcmc.samples <- rstan::extract(stan.res)$theta
mcmc.mu <- colMeans(mcmc.samples)
mcmc.Sigma <- var(mcmc.samples)

# Plotting results
for (j in 1:(p + 1)) {
  curve(demp(x, obs = mcmc.samples[, j]),
        from = mcmc.mu[j] - 5*sqrt(mcmc.Sigma[j, j]),
        to = mcmc.mu[j] + 5*sqrt(mcmc.Sigma[j, j]))
  abline(v = mcmc.mu[j], lty = 2)
  curve(dnorm(x, ep.mu[j], sqrt(ep.Sigma[j, j])), col = "red", add = TRUE)
}
```

## Benchmark 2

```{r Benchmark 2}
set.seed(1)

# Data
load("../Benchmark-data/Prostate.RData")
X <- cbind(1, scale(Prostate[, -9]))
y <- Prostate[, 9]
n <- nrow(X)
p <- ncol(X)

# EP approximation
ep.res <- ep.approx(X, y, mu.kappa, sigma.2.kappa, 
                    lambda.1, lambda.2, eta = 0.5, alpha = 1, Q.star = 0.01*diag(2), r.star = rep(0, 2), prec = 0,
                    min.passes = 6, max.passes = 200, tol.factor = Inf, stop.factor = Inf , 
                    abs.thresh = 0.01, rel.thresh = 0.9, delta.limit = Inf, patience = 40, verbose = T)
ep.mu <- ep.res$mu
ep.Sigma <- ep.res$Sigma

# MCMC approximation
stan.res <- stan(file = "Elastic-net-model.stan",
                 data = list(N = n,
                             p = p,
                             X = X,
                             y = y,
                             mu_kappa = mu.kappa,
                             sigma_2_kappa = sigma.2.kappa,
                             lambda_1 = lambda.1,
                             lambda_2 = lambda.2),
                 chains = 1,
                 iter = 50000,
                 warmup = 5000,
                 init = "random") 

mcmc.samples <- rstan::extract(stan.res)$theta
mcmc.mu <- colMeans(mcmc.samples)
mcmc.Sigma <- var(mcmc.samples)

# Plotting results
for (j in 1:(p + 1)) {
  curve(demp(x, obs = mcmc.samples[, j]),
        from = mcmc.mu[j] - 5*sqrt(mcmc.Sigma[j, j]),
        to = mcmc.mu[j] + 5*sqrt(mcmc.Sigma[j, j]))
  abline(v = mcmc.mu[j], lty = 2)
  curve(dnorm(x, ep.mu[j], sqrt(ep.Sigma[j, j])), col = "red", add = TRUE)
}
```

## Benchmark 3

```{r Benchmark 3}
set.seed(1)

# Data
load("../Benchmark-data/eyedata.RData")
X <- cbind(1, scale(unname(x)))
y <- y
n <- nrow(X)
p <- ncol(X)

# EP approximation
ep.res <- ep.approx(X, y, mu.kappa, sigma.2.kappa, 
                    lambda.1, lambda.2, eta = 0.5, alpha = 1, Q.star = 0.01*diag(2), r.star = rep(0, 2), prec = 0,
                    min.passes = 6, max.passes = 200, tol.factor = Inf, stop.factor = Inf , 
                    abs.thresh = 5, rel.thresh = 0.9, delta.limit = Inf, patience = 40, verbose = T)
ep.mu <- ep.res$mu
ep.Sigma <- ep.res$Sigma

# MCMC approximation
stan.res <- stan(file = "Elastic-net-model.stan",
                 data = list(N = n,
                             p = p,
                             X = X,
                             y = y,
                             mu_kappa = mu.kappa,
                             sigma_2_kappa = sigma.2.kappa,
                             lambda_1 = lambda.1,
                             lambda_2 = lambda.2),
                 chains = 1,
                 iter = 50000,
                 warmup = 5000,
                 init = "random") 

mcmc.samples <- rstan::extract(stan.res)$theta
mcmc.mu <- colMeans(mcmc.samples)
mcmc.Sigma <- var(mcmc.samples)

# Plotting results
for (j in 1:(p + 1)) {
  curve(demp(x, obs = mcmc.samples[, j]),
        from = mcmc.mu[j] - 5*sqrt(mcmc.Sigma[j, j]),
        to = mcmc.mu[j] + 5*sqrt(mcmc.Sigma[j, j]))
  abline(v = mcmc.mu[j], lty = 2)
  curve(dnorm(x, ep.mu[j], sqrt(ep.Sigma[j, j])), col = "red", add = TRUE)
}
```
